{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4GQDvCY25I4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_curve, auc, make_scorer\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('40415474_features.csv')\n",
        "data['is_letter'] = data['label'].isin(list('abcdefghij')).astype(int)\n",
        "\n",
        "X = data[['nr_pix', 'aspect_ratio']]\n",
        "y = data['is_letter']\n",
        "\n",
        "# SECTION 1.1: 80/20 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Confusion matrix\n",
        "cm1 = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
        "plt.title('Confusion Matrix (Section 1.1)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Metrics\n",
        "acc1 = accuracy_score(y_test, y_pred)\n",
        "prec1 = precision_score(y_test, y_pred)\n",
        "rec1 = recall_score(y_test, y_pred)\n",
        "f1_1 = f1_score(y_test, y_pred)\n",
        "fpr1 = cm1[0,1] / (cm1[0,1] + cm1[0,0])\n",
        "\n",
        "print(\"=== Section 1.1 Metrics ===\")\n",
        "print(f\"Accuracy: {acc1:.2%}\")\n",
        "print(f\"Precision: {prec1:.2%}\")\n",
        "print(f\"Recall (TPR): {rec1:.2%}\")\n",
        "print(f\"False Positive Rate: {fpr1:.2%}\")\n",
        "print(f\"F1-score: {f1_1:.2%}\")\n",
        "\n",
        "# SECTION 1.2: 5-fold CV predictions\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "y_pred_cv = cross_val_predict(\n",
        "    model, X, y, cv=cv, method='predict'\n",
        ")\n",
        "y_prob_cv = cross_val_predict(\n",
        "    model, X, y, cv=cv, method='predict_proba'\n",
        ")[:, 1]\n",
        "\n",
        "cm2 = confusion_matrix(y, y_pred_cv)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm2, annot=True, fmt='d', cmap='Greens', cbar=False,\n",
        "            xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
        "plt.title('Confusion Matrix (5-Fold CV)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "acc2 = accuracy_score(y, y_pred_cv)\n",
        "prec2 = precision_score(y, y_pred_cv)\n",
        "rec2 = recall_score(y, y_pred_cv)\n",
        "f1_2 = f1_score(y, y_pred_cv)\n",
        "fpr2 = cm2[0,1] / (cm2[0,1] + cm2[0,0])\n",
        "\n",
        "print(\"\\n=== Section 1.2 Metrics (5-Fold CV) ===\")\n",
        "print(f\"Accuracy: {acc2:.2%}\")\n",
        "print(f\"Precision: {prec2:.2%}\")\n",
        "print(f\"Recall (TPR): {rec2:.2%}\")\n",
        "print(f\"False Positive Rate: {fpr2:.2%}\")\n",
        "print(f\"F1-score: {f1_2:.2%}\")\n",
        "\n",
        "# SECTION 1.3: ROC curves for both\n",
        "fpr1_curve, tpr1_curve, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc1 = auc(fpr1_curve, tpr1_curve)\n",
        "\n",
        "fpr2_curve, tpr2_curve, _ = roc_curve(y, y_prob_cv)\n",
        "roc_auc2 = auc(fpr2_curve, tpr2_curve)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(fpr1_curve, tpr1_curve, label=f'Section 1.1 (AUC {roc_auc1:.2f})')\n",
        "plt.plot(fpr2_curve, tpr2_curve, linestyle='--',\n",
        "         label=f'5-Fold CV (AUC {roc_auc2:.2f})')\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}