{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4GQDvCY25I4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Load and prepare data\n",
        "data = pd.read_csv(r'40415474/40415474_features.csv')\n",
        "\n",
        "# Filter for 4 classes: a, j, smile, sad, xclaim\n",
        "selected_classes = ['a', 'j', 'smile', 'sad', 'xclaim']\n",
        "filtered_data = data[data['label'].isin(selected_classes)].copy()\n",
        "\n",
        "# Create numeric class codes (4-way classification)\n",
        "class_mapping = {\n",
        "    'a': 0, 'j': 1,      # Letters (kept separate as per assignment specs)\n",
        "    'smile': 2,           # Happy faces\n",
        "    'sad': 3,             # Sad faces\n",
        "    'xclaim': 4           # Exclamation marks\n",
        "}\n",
        "filtered_data['class_code'] = filtered_data['label'].map(class_mapping)\n",
        "\n",
        "# Select features (justify your choice in report)\n",
        "selected_features = ['nr_pix', 'aspect_ratio', 'rows_with_1', 'cols_with_1']\n",
        "X = filtered_data[selected_features]\n",
        "y = filtered_data['class_code']\n",
        "\n",
        "# 2.1 KNN on Training Data (all 76 items)\n",
        "k_values = list(range(1, 14, 2))  # Odd k from 1 to 13\n",
        "train_accuracies = []\n",
        "\n",
        "print(\"=== Section 2.1 ===\")\n",
        "print(\"Training Accuracies:\")\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X, y)\n",
        "    train_acc = knn.score(X, y)\n",
        "    train_accuracies.append(train_acc)\n",
        "    print(f\"k={k}: {train_acc:.4f}\")\n",
        "\n",
        "# 2.2 KNN with 5-Fold Cross-Validation\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_accuracies = []\n",
        "\n",
        "print(\"\\n=== Section 2.2 ===\")\n",
        "print(\"Cross-Validated Accuracies:\")\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, X, y, cv=cv)\n",
        "    cv_accuracies.append(scores.mean())\n",
        "    print(f\"k={k}: {scores.mean():.4f}\")\n",
        "\n",
        "# 2.3 Confusion Matrix for Best k\n",
        "best_k = k_values[np.argmax(cv_accuracies)]\n",
        "print(f\"\\n=== Section 2.3 ===\")\n",
        "print(f\"Best k from CV: {best_k}\")\n",
        "\n",
        "# Fit model with best k using all data\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn.fit(X, y)\n",
        "y_pred = knn.predict(X)\n",
        "\n",
        "# Create confusion matrix\n",
        "class_names = ['a', 'j', 'smile', 'sad', 'xclaim']\n",
        "conf_mat = confusion_matrix(y, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(f'Confusion Matrix for k={best_k}')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Find most confusing pairs\n",
        "print(\"\\nMost Difficult Pairs:\")\n",
        "for i in range(len(class_names)):\n",
        "    for j in range(len(class_names)):\n",
        "        if i != j and conf_mat[i,j] > 0:\n",
        "            print(f\"{class_names[i]} vs {class_names[j]}: {conf_mat[i,j]} misclassifications\")\n",
        "\n",
        "# 2.4 Training vs CV Accuracy Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_values, train_accuracies, 'b-o', label='Training Accuracy')\n",
        "plt.plot(k_values, cv_accuracies, 'r-o', label='CV Accuracy')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training vs Cross-Validated Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Annotate points with accuracy values\n",
        "for k, train_acc, cv_acc in zip(k_values, train_accuracies, cv_accuracies):\n",
        "    plt.annotate(f'{train_acc:.2f}', (k, train_acc), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
        "    plt.annotate(f'{cv_acc:.2f}', (k, cv_acc), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Additional plot for 1/k as requested\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(1/np.array(k_values), train_accuracies, 'b-o', label='Training Accuracy')\n",
        "plt.plot(1/np.array(k_values), cv_accuracies, 'r-o', label='CV Accuracy')\n",
        "plt.xlabel('1/k')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs 1/k')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Annotate points with k values\n",
        "for k, inv_k, train_acc, cv_acc in zip(k_values, 1/np.array(k_values), train_accuracies, cv_accuracies):\n",
        "    plt.annotate(f'k={k}', (inv_k, train_acc), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
        "    plt.annotate(f'k={k}', (inv_k, cv_acc), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
